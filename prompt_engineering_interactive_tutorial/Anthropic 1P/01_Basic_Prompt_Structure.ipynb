{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第一章：基本提示结构\n",
    "\n",
    "- [课程](#lesson)\n",
    "- [练习](#exercises)\n",
    "- [示例演练场](#example-playground)\n",
    "\n",
    "## 设置\n",
    "\n",
    "运行以下设置单元格以加载您的API密钥并建立 `get_completion` 辅助函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install anthropic\n",
    "\n",
    "# 导入Python内置的正则表达式库。\n",
    "import re\n",
    "import anthropic\n",
    "\n",
    "# 从IPython存储中检索 API_KEY 和 MODEL_NAME 变量。\n",
    "%store -r API_KEY\n",
    "%store -r MODEL_NAME\n",
    "\n",
    "client = anthropic.Anthropic(api_key=API_KEY)\n",
    "\n",
    "def get_completion(prompt: str, system_prompt=\"\"):\n",
    "    message = client.messages.create(\n",
    "        model=MODEL_NAME,\n",
    "        max_tokens=2000,\n",
    "        temperature=0.0,\n",
    "        system=system_prompt,\n",
    "        messages=[\n",
    "          {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "    )\n",
    "    return message.content[0].text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 课程\n",
    "\n",
    "Anthropic提供两种API：旧版的[文本补全API（Text Completions API）](https://docs.anthropic.com/claude/reference/complete_post)和当前的[消息API（Messages API）](https://docs.anthropic.com/claude/reference/messages_post)。本教程中，我们将专门使用消息API。\n",
    "\n",
    "使用消息API调用Claude至少需要以下参数：\n",
    "- `model`: 您打算调用的模型的[API模型名称](https://docs.anthropic.com/claude/docs/models-overview#model-recommendations)。\n",
    "\n",
    "- `max_tokens`: 在停止生成之前要生成的最大token数量。请注意，Claude可能会在达到此最大值之前停止。此参数仅指定要生成的绝对最大token数量。此外，这是一个*硬性*停止，这意味着它可能导致Claude在生成单词或句子中途停止。\n",
    "\n",
    "- `messages`: 一个输入消息数组。我们的模型经过训练，可以在交替的 `user`（用户）和 `assistant`（助手）对话轮次中运行。创建新的 `Message` 时，您可以通过 `messages` 参数指定之前的对话轮次，然后模型会生成对话中的下一个 `Message`。\n",
    "  - 每个输入消息必须是一个包含 `role`（角色）和 `content`（内容）的对象。您可以指定一个 `user` 角色的消息，或者包含多个 `user` 和 `assistant` 消息（如果包含多个，它们必须交替出现）。第一个消息必须始终使用 `user` 角色。\n",
    "\n",
    "还有一些可选参数，例如：\n",
    "- `system`: 系统提示——更多内容将在下面讨论。\n",
    "\n",
    "- `temperature`: Claude响应的可变性程度。对于这些课程和练习，我们将 `temperature` 设置为0。\n",
    "\n",
    "有关所有API参数的完整列表，请访问我们的[API文档](https://docs.anthropic.com/claude/reference/messages_post)。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 示例\n",
    "\n",
    "让我们看看Claude如何响应一些格式正确的提示。对于以下每个单元格，运行该单元格（`shift+enter`），Claude的响应将出现在代码块下方。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 提示\n",
    "PROMPT = \"Hi Claude, how are you?\"\n",
    "\n",
    "# 打印 Claude 的响应\n",
    "print(get_completion(PROMPT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 提示\n",
    "PROMPT = \"你能告诉我海洋的颜色吗?\"\n",
    "\n",
    "# 打印 Claude 的响应\n",
    "print(get_completion(PROMPT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 提示\n",
    "PROMPT = \"席琳·迪翁是哪一年出生的？\"\n",
    "\n",
    "# 打印 Claude 的响应\n",
    "print(get_completion(PROMPT))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在，让我们看看一些不包含正确Messages API格式的提示。对于这些格式错误的提示，Messages API会返回一个错误。\n",
    "\n",
    "首先，我们有一个Messages API调用示例，其中 `messages` 数组缺少 `role` 和 `content` 字段。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取 Claude 的响应\n",
    "response = client.messages.create(\n",
    "        model=MODEL_NAME,\n",
    "        max_tokens=2000,\n",
    "        temperature=0.0,\n",
    "        messages=[\n",
    "          {\"Hi Claude, how are you?\"}\n",
    "        ]\n",
    "    )\n",
    "\n",
    "# 打印 Claude 的响应\n",
    "print(response[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这是一个未能交替使用 `user` 和 `assistant` 角色的提示。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取 Claude 的响应\n",
    "response = client.messages.create(\n",
    "        model=MODEL_NAME,\n",
    "        max_tokens=2000,\n",
    "        temperature=0.0,\n",
    "        messages=[\n",
    "          {\"role\": \"user\", \"content\": \"席琳·迪翁是哪一年出生的？\"},\n",
    "          {\"role\": \"user\", \"content\": \"而且, 你能告诉我一些关于她的其他事实吗？\"}\n",
    "        ]\n",
    "    )\n",
    "\n",
    "# 打印 Claude 的响应\n",
    "print(response[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`user` 和 `assistant` 消息**必须交替出现**，并且消息**必须以 `user` 轮次开始**。您可以在提示中包含多个 `user` 和 `assistant` 对（就像模拟多轮对话一样）。您也可以在末尾的 `assistant` 消息中填入一些词语，让Claude从您中断的地方继续（这将在后续章节中详细介绍）。\n",
    "\n",
    "#### 系统提示\n",
    "\n",
    "您还可以使用**系统提示**。系统提示是一种在“用户”轮次中向Claude提出问题或任务之前，**为其提供上下文、指令和指导**的方式。\n",
    "\n",
    "从结构上讲，系统提示独立于 `user` 和 `assistant` 消息列表，因此属于一个单独的 `system` 参数（请查看Notebook [设置](#setup) 部分中 `get_completion` 辅助函数的结构）。\n",
    "\n",
    "在本教程中，凡是可能用到系统提示的地方，我们都在您的补全函数中为您提供了 `system` 字段。如果您不想使用系统提示，只需将 `SYSTEM_PROMPT` 变量设置为空字符串即可。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 系统提示示例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 系统提示\n",
    "SYSTEM_PROMPT = \"你的回答应该总是一系列批判性思维问题，以推动对话（不要提供问题的答案）。不要实际回答用户的问题。\"\n",
    "\n",
    "# 提示\n",
    "PROMPT = \"天空为什么是蓝的？\"\n",
    "\n",
    "# 打印 Claude 的响应\n",
    "print(get_completion(PROMPT, SYSTEM_PROMPT))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "为什么要使用系统提示？一个**精心编写的系统提示可以从多方面提升Claude的性能**，例如增强Claude遵循规则和指令的能力。欲了解更多信息，请访问我们关于[如何与Claude一起使用系统提示](https://docs.anthropic.com/claude/docs/how-to-use-system-prompts)的文档。\n",
    "\n",
    "现在我们将深入一些练习。如果您想在不更改上方任何内容的情况下，尝试课程中的提示，请一直滚动到课程Notebook的底部，访问[**示例演练场**](#example-playground)。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 练习\n",
    "- [练习 1.1 - 数到三](#exercise-11---counting-to-three)\n",
    "- [练习 1.2 - 系统提示](#exercise-12---system-prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 练习 1.1 - 数到三\n",
    "使用正确的 `user` / `assistant` 格式，编辑下面的 `PROMPT`，让Claude**数到三**。输出还将指示您的解决方案是否正确。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 提示 - 这是您唯一需要更改的字段\n",
    "PROMPT = \"[替换此文本]\"\n",
    "\n",
    "# 获取Claude的响应\n",
    "response = get_completion(PROMPT)\n",
    "\n",
    "# 评估练习正确性的函数\n",
    "def grade_exercise(text):\n",
    "    pattern = re.compile(r'^(?=.*1)(?=.*2)(?=.*3).*$', re.DOTALL)\n",
    "    return bool(pattern.match(text))\n",
    "\n",
    "# 打印Claude的响应和相应的评分\n",
    "print(response)\n",
    "print(\"\\n--------------------------- 评分 ---------------------------\")\n",
    "print(\"此练习已正确解决：\", grade_exercise(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❓ 如果您想要提示，请运行下面的单元格！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hints import exercise_1_1_hint; print(exercise_1_1_hint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 练习 1.2 - 系统提示\n",
    "\n",
    "修改 `SYSTEM_PROMPT`，让Claude像一个3岁小孩一样回应。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 系统提示 - 这是您唯一需要更改的字段\n",
    "SYSTEM_PROMPT = \"[替换此文本]\"\n",
    "\n",
    "# 提示\n",
    "PROMPT = \"天空有多大？\"\n",
    "\n",
    "# 获取Claude的响应\n",
    "response = get_completion(PROMPT, SYSTEM_PROMPT)\n",
    "\n",
    "# 评估练习正确性的函数\n",
    "def grade_exercise(text):\n",
    "    return bool(re.search(r\"giggles\", text) or re.search(r\"soo\", text))\n",
    "\n",
    "# 打印Claude的响应和相应的评分\n",
    "print(response)\n",
    "print(\"\\n--------------------------- 评分 ---------------------------\")\n",
    "print(\"此练习已正确解决：\", grade_exercise(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❓ 如果您想要提示，请运行下面的单元格！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hints import exercise_1_2_hint; print(exercise_1_2_hint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 恭喜！\n",
    "\n",
    "如果您已经解决了到目前为止的所有练习，那么您已准备好进入下一章。祝您提示愉快！\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 1: Basic Prompt Structure\n",
    "\n",
    "- [Lesson](#lesson)\n",
    "- [Exercises](#exercises)\n",
    "- [Example Playground](#example-playground)\n",
    "\n",
    "## Setup\n",
    "\n",
    "Run the following setup cell to load your API key and establish the `get_completion` helper function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install anthropic\n",
    "\n",
    "# Import python's built-in regular expression library\n",
    "import re\n",
    "import anthropic\n",
    "\n",
    "# Retrieve the API_KEY & MODEL_NAME variables from the IPython store\n",
    "%store -r API_KEY\n",
    "%store -r MODEL_NAME\n",
    "\n",
    "client = anthropic.Anthropic(api_key=API_KEY)\n",
    "\n",
    "def get_completion(prompt: str, system_prompt=\"\"):\n",
    "    message = client.messages.create(\n",
    "        model=MODEL_NAME,\n",
    "        max_tokens=2000,\n",
    "        temperature=0.0,\n",
    "        system=system_prompt,\n",
    "        messages=[\n",
    "          {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "    )\n",
    "    return message.content[0].text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Lesson\n",
    "\n",
    "Anthropic offers two APIs, the legacy [Text Completions API](https://docs.anthropic.com/claude/reference/complete_post) and the current [Messages API](https://docs.anthropic.com/claude/reference/messages_post). For this tutorial, we will be exclusively using the Messages API.\n",
    "\n",
    "At minimum, a call to Claude using the Messages API requires the following parameters:\n",
    "- `model`: the [API model name](https://docs.anthropic.com/claude/docs/models-overview#model-recommendations) of the model that you intend to call\n",
    "\n",
    "- `max_tokens`: the maximum number of tokens to generate before stopping. Note that Claude may stop before reaching this maximum. This parameter only specifies the absolute maximum number of tokens to generate. Furthermore, this is a *hard* stop, meaning that it may cause Claude to stop generating mid-word or mid-sentence.\n",
    "\n",
    "- `messages`: an array of input messages. Our models are trained to operate on alternating `user` and `assistant` conversational turns. When creating a new `Message`, you specify the prior conversational turns with the messages parameter, and the model then generates the next `Message` in the conversation.\n",
    "  - Each input message must be an object with a `role` and `content`. You can specify a single `user`-role message, or you can include multiple `user` and `assistant` messages (they must alternate, if so). The first message must always use the `user` role.\n",
    "\n",
    "There are also optional parameters, such as:\n",
    "- `system`: the system prompt - more on this below.\n",
    "  \n",
    "- `temperature`: the degree of variability in Claude's response. For these lessons and exercises, we have set `temperature` to 0.\n",
    "\n",
    "For a complete list of all API parameters, visit our [API documentation](https://docs.anthropic.com/claude/reference/messages_post)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examples\n",
    "\n",
    "Let's take a look at how Claude responds to some correctly-formatted prompts. For each of the following cells, run the cell (`shift+enter`), and Claude's response will appear below the block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt\n",
    "PROMPT = \"Hi Claude, how are you?\"\n",
    "\n",
    "# Print Claude's response\n",
    "print(get_completion(PROMPT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt\n",
    "PROMPT = \"Can you tell me the color of the ocean?\"\n",
    "\n",
    "# Print Claude's response\n",
    "print(get_completion(PROMPT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt\n",
    "PROMPT = \"What year was Celine Dion born in?\"\n",
    "\n",
    "# Print Claude's response\n",
    "print(get_completion(PROMPT))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's take a look at some prompts that do not include the correct Messages API formatting. For these malformatted prompts, the Messages API returns an error.\n",
    "\n",
    "First, we have an example of a Messages API call that lacks `role` and `content` fields in the `messages` array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Claude's response\n",
    "response = client.messages.create(\n",
    "        model=MODEL_NAME,\n",
    "        max_tokens=2000,\n",
    "        temperature=0.0,\n",
    "        messages=[\n",
    "          {\"Hi Claude, how are you?\"}\n",
    "        ]\n",
    "    )\n",
    "\n",
    "# Print Claude's response\n",
    "print(response[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a prompt that fails to alternate between the `user` and `assistant` roles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Claude's response\n",
    "response = client.messages.create(\n",
    "        model=MODEL_NAME,\n",
    "        max_tokens=2000,\n",
    "        temperature=0.0,\n",
    "        messages=[\n",
    "          {\"role\": \"user\", \"content\": \"What year was Celine Dion born in?\"},\n",
    "          {\"role\": \"user\", \"content\": \"Also, can you tell me some other facts about her?\"}\n",
    "        ]\n",
    "    )\n",
    "\n",
    "# Print Claude's response\n",
    "print(response[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`user` and `assistant` messages **MUST alternate**, and messages **MUST start with a `user` turn**. You can have multiple `user` & `assistant` pairs in a prompt (as if simulating a multi-turn conversation). You can also put words into a terminal `assistant` message for Claude to continue from where you left off (more on that in later chapters).\n",
    "\n",
    "#### System Prompts\n",
    "\n",
    "You can also use **system prompts**. A system prompt is a way to **provide context, instructions, and guidelines to Claude** before presenting it with a question or task in the \"User\" turn. \n",
    "\n",
    "Structurally, system prompts exist separately from the list of `user` & `assistant` messages, and thus belong in a separate `system` parameter (take a look at the structure of the `get_completion` helper function in the [Setup](#setup) section of the notebook). \n",
    "\n",
    "Within this tutorial, wherever we might utilize a system prompt, we have provided you a `system` field in your completions function. Should you not want to use a system prompt, simply set the `SYSTEM_PROMPT` variable to an empty string."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### System Prompt Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# System prompt\n",
    "SYSTEM_PROMPT = \"Your answer should always be a series of critical thinking questions that further the conversation (do not provide answers to your questions). Do not actually answer the user question.\"\n",
    "\n",
    "# Prompt\n",
    "PROMPT = \"Why is the sky blue?\"\n",
    "\n",
    "# Print Claude's response\n",
    "print(get_completion(PROMPT, SYSTEM_PROMPT))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why use a system prompt? A **well-written system prompt can improve Claude's performance** in a variety of ways, such as increasing Claude's ability to follow rules and instructions. For more information, visit our documentation on [how to use system prompts](https://docs.anthropic.com/claude/docs/how-to-use-system-prompts) with Claude.\n",
    "\n",
    "Now we'll dive into some exercises. If you would like to experiment with the lesson prompts without changing any content above, scroll all the way to the bottom of the lesson notebook to visit the [**Example Playground**](#example-playground)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Exercises\n",
    "- [Exercise 1.1 - Counting to Three](#exercise-11---counting-to-three)\n",
    "- [Exercise 1.2 - System Prompt](#exercise-12---system-prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1.1 - Counting to Three\n",
    "Using proper `user` / `assistant` formatting, edit the `PROMPT` below to get Claude to **count to three.** The output will also indicate whether your solution is correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt - this is the only field you should change\n",
    "PROMPT = \"[Replace this text]\"\n",
    "\n",
    "# Get Claude's response\n",
    "response = get_completion(PROMPT)\n",
    "\n",
    "# Function to grade exercise correctness\n",
    "def grade_exercise(text):\n",
    "    pattern = re.compile(r'^(?=.*1)(?=.*2)(?=.*3).*$', re.DOTALL)\n",
    "    return bool(pattern.match(text))\n",
    "\n",
    "# Print Claude's response and the corresponding grade\n",
    "print(response)\n",
    "print(\"\\n--------------------------- GRADING ---------------------------\")\n",
    "print(\"This exercise has been correctly solved:\", grade_exercise(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❓ If you want a hint, run the cell below!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hints import exercise_1_1_hint; print(exercise_1_1_hint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1.2 - System Prompt\n",
    "\n",
    "Modify the `SYSTEM_PROMPT` to make Claude respond like it's a 3 year old child."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# System prompt - this is the only field you should change\n",
    "SYSTEM_PROMPT = \"[Replace this text]\"\n",
    "\n",
    "# Prompt\n",
    "PROMPT = \"How big is the sky?\"\n",
    "\n",
    "# Get Claude's response\n",
    "response = get_completion(PROMPT, SYSTEM_PROMPT)\n",
    "\n",
    "# Function to grade exercise correctness\n",
    "def grade_exercise(text):\n",
    "    return bool(re.search(r\"giggles\", text) or re.search(r\"soo\", text))\n",
    "\n",
    "# Print Claude's response and the corresponding grade\n",
    "print(response)\n",
    "print(\"\\n--------------------------- GRADING ---------------------------\")\n",
    "print(\"This exercise has been correctly solved:\", grade_exercise(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❓ If you want a hint, run the cell below!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hints import exercise_1_2_hint; print(exercise_1_2_hint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Congrats!\n",
    "\n",
    "If you've solved all exercises up until this point, you're ready to move to the next chapter. Happy prompting!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Example Playground\n",
    "\n",
    "This is an area for you to experiment freely with the prompt examples shown in this lesson and tweak prompts to see how it may affect Claude's responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt\n",
    "PROMPT = \"Hi Claude, how are you?\"\n",
    "\n",
    "# Print Claude's response\n",
    "print(get_completion(PROMPT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt\n",
    "PROMPT = \"Can you tell me the color of the ocean?\"\n",
    "\n",
    "# Print Claude's response\n",
    "print(get_completion(PROMPT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt\n",
    "PROMPT = \"What year was Celine Dion born in?\"\n",
    "\n",
    "# Print Claude's response\n",
    "print(get_completion(PROMPT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Claude's response\n",
    "response = client.messages.create(\n",
    "        model=MODEL_NAME,\n",
    "        max_tokens=2000,\n",
    "        temperature=0.0,\n",
    "        messages=[\n",
    "          {\"Hi Claude, how are you?\"}\n",
    "        ]\n",
    "    )\n",
    "\n",
    "# Print Claude's response\n",
    "print(response[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Claude's response\n",
    "response = client.messages.create(\n",
    "        model=MODEL_NAME,\n",
    "        max_tokens=2000,\n",
    "        temperature=0.0,\n",
    "        messages=[\n",
    "          {\"role\": \"user\", \"content\": \"What year was Celine Dion born in?\"},\n",
    "          {\"role\": \"user\", \"content\": \"Also, can you tell me some other facts about her?\"}\n",
    "        ]\n",
    "    )\n",
    "\n",
    "# Print Claude's response\n",
    "print(response[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# System prompt\n",
    "SYSTEM_PROMPT = \"Your answer should always be a series of critical thinking questions that further the conversation (do not provide answers to your questions). Do not actually answer the user question.\"\n",
    "\n",
    "# Prompt\n",
    "PROMPT = \"Why is the sky blue?\"\n",
    "\n",
    "# Print Claude's response\n",
    "print(get_completion(PROMPT, SYSTEM_PROMPT))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
