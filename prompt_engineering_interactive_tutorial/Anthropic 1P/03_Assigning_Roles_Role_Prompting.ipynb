{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 第三章：分配角色（角色提示）\n",
                "\n",
                "- [课程](#lesson)\n",
                "- [练习](#exercises)\n",
                "- [示例演练场](#example-playground)\n",
                "\n",
                "## 设置\n",
                "\n",
                "运行以下设置单元格，加载您的 API 密钥并建立 `get_completion` 辅助函数。"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "%pip install anthropic\n",
                "\n",
                "# 导入 Python 内置的正则表达式库\n",
                "import re\n",
                "import anthropic\n",
                "\n",
                "# 从 IPython 存储中检索 API_KEY 和 MODEL_NAME 变量\n",
                "%store -r API_KEY\n",
                "%store -r MODEL_NAME\n",
                "\n",
                "client = anthropic.Anthropic(api_key=API_KEY)\n",
                "\n",
                "def get_completion(prompt: str, system_prompt=\"\"):\n",
                "    message = client.messages.create(\n",
                "        model=MODEL_NAME,\n",
                "        max_tokens=2000,\n",
                "        temperature=0.0,\n",
                "        system=system_prompt,\n",
                "        messages=[\n",
                "          {\"role\": \"user\", \"content\": prompt}\n",
                "        ]\n",
                "    )\n",
                "    return message.content[0].text"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## 课程\n",
                "\n",
                "延续之前关于 Claude 除了你所说的内容之外没有其他上下文的主题，有时重要的是**提示 Claude 扮演一个特定的角色（包括所有必要的上下文）**。这也被称为角色提示。角色上下文的细节越丰富越好。\n",
                "\n",
                "**通过角色预设（Priming Claude with a role）可以提高 Claude 在各种领域的表现**，从写作到编码再到总结。这就像人类有时被告知“像一个______一样思考”时会得到帮助一样。角色提示还可以改变 Claude 响应的风格、语气和方式。\n",
                "\n",
                "**注意**：角色提示既可以在系统提示中进行，也可以作为用户消息回合的一部分。"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 示例\n",
                "\n",
                "在下面的示例中，我们看到，在没有角色提示的情况下，当被要求就滑板运动提供一句观点时，Claude 提供了一个**直接且非风格化的答案**。\n",
                "\n",
                "然而，当我们预设 Claude 扮演一只猫的角色时，Claude 的视角发生了变化，因此**Claude 的响应语气、风格和内容都适应了新角色**。\n",
                "\n",
                "**注意**：一个你可以使用的额外技巧是**向 Claude 提供其目标受众的上下文**。在下方，我们可以调整提示，同时告诉 Claude 它应该向谁说话。“你是一只猫”会产生与“你是一只猫，正在向一群滑板爱好者讲话”截然不同的响应。\n",
                "\n",
                "以下是没有在系统提示中进行角色提示的提示："
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 提示\n",
                "PROMPT = \"用一句话，你对滑板运动有什么看法？\"\n",
                "\n",
                "# 打印 Claude 的响应\n",
                "print(get_completion(PROMPT))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "这里是相同的用户问题，但这次加入了角色提示。"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 系统提示\n",
                "SYSTEM_PROMPT = \"你是一只猫。\"\n",
                "\n",
                "# 提示\n",
                "PROMPT = \"用一句话，你对滑板运动有什么看法？\"\n",
                "\n",
                "# 打印 Claude 的响应\n",
                "print(get_completion(PROMPT, SYSTEM_PROMPT))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "你可以使用角色提示来让 Claude 模仿特定的写作风格、以某种声音说话，或者引导其回答的复杂程度。**角色提示还可以让 Claude 在执行数学或逻辑任务时表现得更好。**\n",
                "\n",
                "例如，在下面的示例中，有一个明确的正确答案，即“是”。然而，Claude 却答错了，并且认为它缺少信息，但实际上它并不缺少："
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 提示\n",
                "PROMPT = \"杰克看着安妮。安妮看着乔治。杰克已婚，乔治未婚，我们不知道安妮是否已婚。请问，是否有一个已婚的人正在看着一个未婚的人？\"\n",
                "\n",
                "# 打印 Claude 的响应\n",
                "print(get_completion(PROMPT))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "现在，如果我们**预设 Claude 扮演一个逻辑机器人**呢？那会如何改变 Claude 的答案？\n",
                "\n",
                "结果是，有了这个新的角色分配，Claude 答对了。（尽管值得注意的是，并非出于所有正确的理由）"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 系统提示\n",
                "SYSTEM_PROMPT = \"你是一个逻辑机器人，旨在回答复杂的逻辑问题。\"\n",
                "\n",
                "# 提示\n",
                "PROMPT = \"杰克看着安妮。安妮看着乔治。杰克已婚，乔治未婚，我们不知道安妮是否已婚。请问，是否有一个已婚的人正在看着一个未婚的人？\"\n",
                "\n",
                "# 打印 Claude 的响应\n",
                "print(get_completion(PROMPT, SYSTEM_PROMPT))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**注意**：在本课程中你将学到，有**许多提示工程技术可以用来获得相似的结果**。使用哪种技术取决于你和你的偏好！我们鼓励你**进行实验，找到你自己的提示工程风格**。\n",
                "\n",
                "如果你想在不改变上方任何内容的情况下，尝试课程中的提示，请一直滚动到课程笔记本的底部，访问[**示例演练场**](#example-playground)。"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## 练习\n",
                "- [练习 3.1 - 数学修正](#exercise-31---math-correction)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 练习 3.1 - 数学修正\n",
                "在某些情况下，**Claude 可能在数学方面表现不佳**，即使是简单的数学。下面，Claude 错误地将一个数学问题评估为已正确解决，尽管第二步中存在一个明显的算术错误。请注意，Claude 在逐步推导时实际上发现了错误，但没有得出整体解决方案是错误的结论。\n",
                "\n",
                "修改`PROMPT`和/或`SYSTEM_PROMPT`，使 Claude 将该解决方案评判为`不正确`，而不是正确解决。"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 系统提示 - 如果你不想使用系统提示，可以将此变量设置为空字符串\n",
                "SYSTEM_PROMPT = \"\"\n",
                "\n",
                "# 提示\n",
                "PROMPT = \"\"\"这个方程在下面解决得正确吗？\n",
                "\n",
                "2x - 3 = 9\n",
                "2x = 6\n",
                "x = 3\"\"\"\n",
                "\n",
                "# 获取 Claude 的响应\n",
                "response = get_completion(PROMPT, SYSTEM_PROMPT)\n",
                "\n",
                "# 评估练习正确性的函数\n",
                "def grade_exercise(text):\n",
                "    if \"incorrect\" in text or \"not correct\" in text.lower():\n",
                "        return True\n",
                "    else:\n",
                "        return False\n",
                "\n",
                "# 打印 Claude 的响应和相应的评分\n",
                "print(response)\n",
                "print(\"\\n--------------------------- 评分 ---------------------------\")\n",
                "print(\"这个练习已正确解决：\", grade_exercise(response))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "❓ 如果你需要提示，运行下面的单元格！"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from hints import exercise_3_1_hint; print(exercise_3_1_hint)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 恭喜！\n",
                "\n",
                "如果你已经解决了到目前为止的所有练习，你就可以进入下一章了。提示愉快！\n",
                "\n",
                "---"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Chapter 3: Assigning Roles (Role Prompting)\n",
                "\n",
                "- [Lesson](#lesson)\n",
                "- [Exercises](#exercises)\n",
                "- [Example Playground](#example-playground)\n",
                "\n",
                "## Setup\n",
                "\n",
                "Run the following setup cell to load your API key and establish the `get_completion` helper function."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "%pip install anthropic\n",
                "\n",
                "# Import python's built-in regular expression library\n",
                "import re\n",
                "import anthropic\n",
                "\n",
                "# Retrieve the API_KEY & MODEL_NAME variables from the IPython store\n",
                "%store -r API_KEY\n",
                "%store -r MODEL_NAME\n",
                "\n",
                "client = anthropic.Anthropic(api_key=API_KEY)\n",
                "\n",
                "def get_completion(prompt: str, system_prompt=\"\"):\n",
                "    message = client.messages.create(\n",
                "        model=MODEL_NAME,\n",
                "        max_tokens=2000,\n",
                "        temperature=0.0,\n",
                "        system=system_prompt,\n",
                "        messages=[\n",
                "          {\"role\": \"user\", \"content\": prompt}\n",
                "        ]\n",
                "    )\n",
                "    return message.content[0].text"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## Lesson\n",
                "\n",
                "Continuing on the theme of Claude having no context aside from what you say, it's sometimes important to **prompt Claude to inhabit a specific role (including all necessary context)**. This is also known as role prompting. The more detail to the role context, the better.\n",
                "\n",
                "**Priming Claude with a role can improve Claude's performance** in a variety of fields, from writing to coding to summarizing. It's like how humans can sometimes be helped when told to \"think like a ______\". Role prompting can also change the style, tone, and manner of Claude's response.\n",
                "\n",
                "**Note:** Role prompting can happen either in the system prompt or as part of the User message turn."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Examples\n",
                "\n",
                "In the example below, we see that without role prompting, Claude provides a **straightforward and non-stylized answer** when asked to give a single sentence perspective on skateboarding.\n",
                "\n",
                "However, when we prime Claude to inhabit the role of a cat, Claude's perspective changes, and thus **Claude's response tone, style, content adapts to the new role**. \n",
                "\n",
                "**Note:** A bonus technique you can use is to **provide Claude context on its intended audience**. Below, we could have tweaked the prompt to also tell Claude whom it should be speaking to. \"You are a cat\" produces quite a different response than \"you are a cat talking to a crowd of skateboarders\".\n",
                "\n",
                "Here is the prompt without role prompting in the system prompt:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Prompt\n",
                "PROMPT = \"In one sentence, what do you think about skateboarding?\"\n",
                "\n",
                "# Print Claude's response\n",
                "print(get_completion(PROMPT))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Here is the same user question, except with role prompting."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# System prompt\n",
                "SYSTEM_PROMPT = \"You are a cat.\"\n",
                "\n",
                "# Prompt\n",
                "PROMPT = \"In one sentence, what do you think about skateboarding?\"\n",
                "\n",
                "# Print Claude's response\n",
                "print(get_completion(PROMPT, SYSTEM_PROMPT))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "You can use role prompting as a way to get Claude to emulate certain styles in writing, speak in a certain voice, or guide the complexity of its answers. **Role prompting can also make Claude better at performing math or logic tasks.**\n",
                "\n",
                "For example, in the example below, there is a definitive correct answer, which is yes. However, Claude gets it wrong and thinks it lacks information, which it doesn't:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Prompt\n",
                "PROMPT = \"Jack is looking at Anne. Anne is looking at George. Jack is married, George is not, and we don’t know if Anne is married. Is a married person looking at an unmarried person?\"\n",
                "\n",
                "# Print Claude's response\n",
                "print(get_completion(PROMPT))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Now, what if we **prime Claude to act as a logic bot**? How will that change Claude's answer? \n",
                "\n",
                "It turns out that with this new role assignment, Claude gets it right. (Although notably not for all the right reasons)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# System prompt\n",
                "SYSTEM_PROMPT = \"You are a logic bot designed to answer complex logic problems.\"\n",
                "\n",
                "# Prompt\n",
                "PROMPT = \"Jack is looking at Anne. Anne is looking at George. Jack is married, George is not, and we don’t know if Anne is married. Is a married person looking at an unmarried person?\"\n",
                "\n",
                "# Print Claude's response\n",
                "print(get_completion(PROMPT, SYSTEM_PROMPT))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Note:** What you'll learn throughout this course is that there are **many prompt engineering techniques you can use to derive similar results**. Which techniques you use is up to you and your preference! We encourage you to **experiment to find your own prompt engineering style**.\n",
                "\n",
                "If you would like to experiment with the lesson prompts without changing any content above, scroll all the way to the bottom of the lesson notebook to visit the [**Example Playground**](#example-playground)."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## Exercises\n",
                "- [Exercise 3.1 - Math Correction](#exercise-31---math-correction)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Exercise 3.1 - Math Correction\n",
                "In some instances, **Claude may struggle with mathematics**, even simple mathematics. Below, Claude incorrectly assesses the math problem as correctly solved, even though there's an obvious arithmetic mistake in the second step. Note that Claude actually catches the mistake when going through step-by-step, but doesn't jump to the conclusion that the overall solution is wrong.\n",
                "\n",
                "Modify the `PROMPT` and / or the `SYSTEM_PROMPT` to make Claude grade the solution as `incorrectly` solved, rather than correctly solved. \n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# System prompt - if you don't want to use a system prompt, you can leave this variable set to an empty string\n",
                "SYSTEM_PROMPT = \"\"\n",
                "\n",
                "# Prompt\n",
                "PROMPT = \"\"\"Is this equation solved correctly below?\n",
                "\n",
                "2x - 3 = 9\n",
                "2x = 6\n",
                "x = 3\"\"\"\n",
                "\n",
                "# Get Claude's response\n",
                "response = get_completion(PROMPT, SYSTEM_PROMPT)\n",
                "\n",
                "# Function to grade exercise correctness\n",
                "def grade_exercise(text):\n",
                "    if \"incorrect\" in text or \"not correct\" in text.lower():\n",
                "        return True\n",
                "    else:\n",
                "        return False\n",
                "\n",
                "# Print Claude's response and the corresponding grade\n",
                "print(response)\n",
                "print(\"\\n--------------------------- GRADING ---------------------------\")\n",
                "print(\"This exercise has been correctly solved:\", grade_exercise(response))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "❓ If you want a hint, run the cell below!"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from hints import exercise_3_1_hint; print(exercise_3_1_hint)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Congrats!\n",
                "\n",
                "If you've solved all exercises up until this point, you're ready to move to the next chapter. Happy prompting!"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## Example Playground\n",
                "\n",
                "This is an area for you to experiment freely with the prompt examples shown in this lesson and tweak prompts to see how it may affect Claude's responses."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Prompt\n",
                "PROMPT = \"In one sentence, what do you think about skateboarding?\"\n",
                "\n",
                "# Print Claude's response\n",
                "print(get_completion(PROMPT))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# System prompt\n",
                "SYSTEM_PROMPT = \"You are a cat.\"\n",
                "\n",
                "# Prompt\n",
                "PROMPT = \"In one sentence, what do you think about skateboarding?\"\n",
                "\n",
                "# Print Claude's response\n",
                "print(get_completion(PROMPT, SYSTEM_PROMPT))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Prompt\n",
                "PROMPT = \"Jack is looking at Anne. Anne is looking at George. Jack is married, George is not, and we don’t know if Anne is married. Is a married person looking at an unmarried person?\"\n",
                "\n",
                "# Print Claude's response\n",
                "print(get_completion(PROMPT))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# System prompt\n",
                "SYSTEM_PROMPT = \"You are a logic bot designed to answer complex logic problems.\"\n",
                "\n",
                "# Prompt\n",
                "PROMPT = \"Jack is looking at Anne. Anne is looking at George. Jack is married, George is not, and we don’t know if Anne is married. Is a married person looking at an unmarried person?\"\n",
                "\n",
                "# Print Claude's response\n",
                "print(get_completion(PROMPT, SYSTEM_PROMPT))"
            ]
        }
    ],
    "metadata": {
        "language_info": {
            "name": "python"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}